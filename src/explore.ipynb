{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# SISTEMA DE DETECCIÓN DE ENLACES SPAM\n",
                "# ============================================\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import re\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import pickle\n",
                "print(\"Librerias Cargadas\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuración visual\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Cargar datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "url = 'https://breathecode.herokuapp.com/asset/internal-link?id=932&path=url_spam.csv'\n",
                "df = pd.read_csv(url)\n",
                "print(\"Dataset Cargado\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n Información general del dataset:\")\n",
                "print(df.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n Primeras filas:\")\n",
                "print(df.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n Estadísticas descriptivas:\")\n",
                "print(df.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identificar columnas\n",
                "columna_url = df.columns[0]\n",
                "columna_spam = df.columns[1]\n",
                "\n",
                "print(f\"\\nColumnas identificadas:\")\n",
                "print(f\"  - URLs: '{columna_url}'\")\n",
                "print(f\"  - Etiquetas: '{columna_spam}'\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribución de clases\n",
                "print(\"\\n Distribución de clases:\")\n",
                "print(df[columna_spam].value_counts())\n",
                "print(f\"\\nPrcentaje de spam: {df[columna_spam].mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualización 1: Distribución de clases\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Gráfico de barras\n",
                "df[columna_spam].value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red'])\n",
                "axes[0].set_title('Distribución: Spam vs No Spam')\n",
                "axes[0].set_xlabel('Clase (0=No Spam, 1=Spam)')\n",
                "axes[0].set_ylabel('Cantidad')\n",
                "axes[0].set_xticklabels(['No Spam', 'Spam'], rotation=0)\n",
                "\n",
                "# Análisis de longitud de URLs\n",
                "df['longitud_url'] = df[columna_url].str.len()\n",
                "df['longitud_url'].hist(bins=50, ax=axes[1], edgecolor='black', alpha=0.7)\n",
                "axes[1].set_title('Distribución de Longitud de URLs')\n",
                "axes[1].set_xlabel('Longitud (caracteres)')\n",
                "axes[1].set_ylabel('Frecuencia')\n",
                "\n",
                "# Longitud por clase\n",
                "df.boxplot(column='longitud_url', by=columna_spam, ax=axes[2])\n",
                "axes[2].set_title('Longitud de URL por Clase')\n",
                "axes[2].set_xlabel('Clase (0=No Spam, 1=Spam)')\n",
                "axes[2].set_ylabel('Longitud')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n Estadísticas de longitud por clase:\")\n",
                "print(df.groupby(columna_spam)['longitud_url'].describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Análisis de caracteres especiales\n",
                "df['num_puntos'] = df[columna_url].str.count(r'\\.')\n",
                "df['num_guiones'] = df[columna_url].str.count(r'-')\n",
                "df['num_barras'] = df[columna_url].str.count(r'/')\n",
                "df['num_digitos'] = df[columna_url].str.count(r'\\d')\n",
                "\n",
                "print(\"\\n Características promedio por clase:\")\n",
                "features_eda = ['longitud_url', 'num_puntos', 'num_guiones', 'num_barras', 'num_digitos']\n",
                "print(df.groupby(columna_spam)[features_eda].mean())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "PREPROCESAMIENTO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def limpiar_url(url):\n",
                "    \"\"\"\n",
                "    Limpia y tokeniza una URL para el modelo\n",
                "    \"\"\"\n",
                "    if pd.isna(url):\n",
                "        return ''\n",
                "    \n",
                "    # Convertir a minúsculas\n",
                "    url = str(url).lower()\n",
                "    # Quitar protocolo y www\n",
                "    url = url.replace('http://', '').replace('https://', '').replace('www.', '')\n",
                "    \n",
                "    # Separar por caracteres especiales (convertirlos en espacios)\n",
                "    url = re.sub(r'[/\\-_\\.?=&@:+%#\\(\\)\\[\\]]', ' ', url)\n",
                "    \n",
                "    # Quitar espacios múltiples\n",
                "    url = ' '.join(url.split())\n",
                "    \n",
                "    return url"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Aplicar limpieza"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['url_limpia'] = df[columna_url].apply(limpiar_url)\n",
                "\n",
                "print(\"\\n Ejemplos de URLs preprocesadas:\")\n",
                "for i in range(5):\n",
                "    print(f\"\\nOriginal: {df[columna_url].iloc[i]}\")\n",
                "    print(f\"Limpia:   {df['url_limpia'].iloc[i]}\")\n",
                "    print(f\"Spam     {df[columna_spam].iloc[i]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preparar X e y\n",
                "X = df['url_limpia']\n",
                "y = df[columna_spam]\n",
                "\n",
                "# División train/test (80/20)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=42, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f\"\\nDivisión de datos:\")\n",
                "print(f\"  Train: {len(X_train)} URLs ({len(X_train)/len(X)*100:.1f}%)\")\n",
                "print(f\"  Test:  {len(X_test)} URLs ({len(X_test)/len(X)*100:.1f}%)\")\n",
                "print(f\"\\n  Distribución en Train:\")\n",
                "print(f\"    No Spam: {(y_train==0).sum()}\")\n",
                "print(f\"    Spam:    {(y_train==1).sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vectorización con TF-IDF"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(\n",
                "    max_features=1500,   # Top 1500 términos más importantes\n",
                "    ngram_range=(1, 2),  # Unigramas y bigramas\n",
                "    min_df=2,            # Ignorar términos que aparecen en menos de 2 documentos\n",
                "    max_df=0.95          # Ignorar términos muy frecuentes\n",
                ")\n",
                "\n",
                "X_train_vec = vectorizer.fit_transform(X_train)\n",
                "X_test_vec = vectorizer.transform(X_test)\n",
                "\n",
                "print(f\"\\n Vectorización completada:\")\n",
                "print(f\"  Train shape: {X_train_vec.shape}\")\n",
                "print(f\"  Test shape:  {X_test_vec.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "SVM CON PARÁMETROS POR DEFECTO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar SVM \n",
                "svm_base = SVC(kernel='linear', random_state=42)\n",
                "print(\"\\n⏳ Entrenando SVM...\")\n",
                "svm_base.fit(X_train_vec, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predicciones\n",
                "y_pred_train = svm_base.predict(X_train_vec)\n",
                "y_pred_test = svm_base.predict(X_test_vec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Métricas\n",
                "acc_train = accuracy_score(y_train, y_pred_train)\n",
                "acc_test = accuracy_score(y_test, y_pred_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"\\nResultados SVM base:\")\n",
                "print(f\"  Accuracy Train: {acc_train:.4f}\")\n",
                "print(f\"  Accuracy Test:  {acc_test:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n Reporte de clasificación (Test):\")\n",
                "print(classification_report(y_test, y_pred_test, target_names=['No Spam', 'Spam']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matriz de confusión\n",
                "cm = confusion_matrix(y_test, y_pred_test)\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['No Spam', 'Spam'],\n",
                "            yticklabels=['No Spam', 'Spam'])\n",
                "plt.title('Matriz de Confusión - SVM Base')\n",
                "plt.ylabel('Real')\n",
                "plt.xlabel('Predicción')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Analisis de Resultados:\n",
                "1. Verdaderos Negativos (448): URLs que realmente no eran spam y tu modelo también las clasificó como “No Spam”. \n",
                "2. Verdaderos Positivos (110): URLs correctamente identificadas como spam.\n",
                "3. Falsos Positivos (13): URLs legítimas que fueron clasificadas como spam por error.\n",
                "4. Falsos Negativos (29): URLs spam que el modelo no detectó."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "OPTIMIZACIÓN CON GRID SEARCH"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definir grid de hiperparámetros\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10, 100],           # Regularización\n",
                "    'kernel': ['linear', 'rbf'],       # Tipo de kernel\n",
                "    'gamma': ['scale', 'auto', 0.1, 1] # Para kernel rbf\n",
                "}\n",
                "\n",
                "print(\"\\n Buscando mejores hiperparámetros...\")\n",
                "print(f\"Grid de búsqueda: {param_grid}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grid Search con validación cruzada\n",
                "grid_search = GridSearchCV(\n",
                "    SVC(random_state=42),\n",
                "    param_grid,\n",
                "    cv=5,                    # 5-fold cross validation\n",
                "    scoring='accuracy',\n",
                "    n_jobs=-1,              # Usar todos los cores\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "grid_search.fit(X_train_vec, y_train)\n",
                "\n",
                "print(f\"\\nMejores parámetros encontrados:\")\n",
                "print(grid_search.best_params_)\n",
                "print(f\"\\nMejor score en validación cruzada: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mejor modelo\n",
                "svm_optimizado = grid_search.best_estimator_\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluar modelo optimizado\n",
                "y_pred_train_opt = svm_optimizado.predict(X_train_vec)\n",
                "y_pred_test_opt = svm_optimizado.predict(X_test_vec)\n",
                "\n",
                "acc_train_opt = accuracy_score(y_train, y_pred_train_opt)\n",
                "acc_test_opt = accuracy_score(y_test, y_pred_test_opt)\n",
                "\n",
                "print(f\"\\n Resultados SVM optimizado:\")\n",
                "print(f\"  Accuracy Train: {acc_train_opt:.4f}\")\n",
                "print(f\"  Accuracy Test:  {acc_test_opt:.4f}\")\n",
                "\n",
                "print(\"\\n Reporte de clasificación (Test - Optimizado):\")\n",
                "print(classification_report(y_test, y_pred_test_opt, target_names=['No Spam', 'Spam']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matriz de confusión optimizada\n",
                "cm_opt = confusion_matrix(y_test, y_pred_test_opt)\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Greens',\n",
                "            xticklabels=['No Spam', 'Spam'],\n",
                "            yticklabels=['No Spam', 'Spam'])\n",
                "plt.title('Matriz de Confusión - SVM Optimizado')\n",
                "plt.ylabel('Real')\n",
                "plt.xlabel('Predicción')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comparación\n",
                "print(\"\\nCOMPARACIÓN DE MODELOS:\")\n",
                "print(f\"{'Modelo':<20} {'Acc Train':<12} {'Acc Test':<12}\")\n",
                "print(\"-\" * 44)\n",
                "print(f\"{'SVM Base':<20} {acc_train:.4f}       {acc_test:.4f}\")\n",
                "print(f\"{'SVM Optimizado':<20} {acc_train_opt:.4f}       {acc_test_opt:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Analisis de resultados:\n",
                "Esto muestra que el modelo mejoró claramente en la detección de spam, sin aumentar los errores en la otra clase."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "GUARDAR EL MODELO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Guardar vectorizador\n",
                "with open('vectorizer.pkl', 'wb') as f:\n",
                "    pickle.dump(vectorizer, f)\n",
                "print(\"Vectorizador guardado: vectorizer.pkl\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Guardar modelo optimizado\n",
                "with open('svm_spam_detector.pkl', 'wb') as f:\n",
                "    pickle.dump(svm_optimizado, f)\n",
                "print(\"Modelo guardado: svm_spam_detector.pkl\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
